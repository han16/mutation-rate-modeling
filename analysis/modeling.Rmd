---
title: "Modeling"
author: "Shengtong Han"
date: YYYY-MM-DD
output: html_document
---

<!-- The file analysis/chunks.R contains chunks that define default settings
shared across the workflowr files. -->
```{r read-chunk, include=FALSE, cache=FALSE}
knitr::read_chunk("chunks.R")
```

<!-- Update knitr chunk options -->
```{r knitr-opts-chunk, include=FALSE}
```

<!-- Insert the date the file was last updated -->
```{r last-updated, echo=FALSE, results='asis'}
```

<!-- Insert the code version (Git commit SHA1) if Git repository exists and R
 package git2r is installed -->
```{r code-version, echo=FALSE, results='asis'}
```

<!-- Add your analysis here -->

## Session information

## base level


At every genomic locus, observed number of mutations, $y_i$ is modeled as Poisson distribution as 

$y_i \sim Pois(\mu_i)$

There are several covariates affecting the mutation rate, such as tri-nucleotide context, parents' age, etc. To relate the mutation rate to covariates $X_i$, Poisson regression could be one way to do that 

$log(E(y_i|X_i))=log(\mu_i)=X_i^T\beta$

Thus 

$\mu_i=e^{X_i^T\beta}$. 

With parameters estimates, we have 

$\hat{\mu_i}=e^{X_i^T\hat{\beta}}$


If we already have baseline mutation rate, say $\hat{\mu}_{i0}$, we can adjust 

$\mu_i=\hat{\mu}_{i0} e^{X_i^T\beta}$


Mutation rate at single base may be largely influenced by its local context, thus it would be more reasonable to adjust by region level mutation rate. 


$y_i \sim Pois(\hat{\mu}_{i0} e^{X_i^T\beta})$

## region level

It's computationally hard to infer the mutation rate at single base since there are 3B bases in human genome. So consider the window level. Within  a window, collapse all bases together, denote $Y$ by the total number of mutations, assume $X_i$ are the same across all bases, and they share the same baseline mutation rate $\mu_0$.  

$Y \sim Pois(\mu_0e^{X_i\beta})$



With the base level mutation rate estimate, the mutation rate in a region can be obtained simply by adding the locals 

$\hat{\mu}=\sum_i \hat{\mu}_i$

Let $y$ be the observed number of mutations in the same region.  If $y>\hat{\mu}$, observed mutation rate is higher than estimated. 

Define $\lambda$ as the local deviation. Treat the region as a unit, similarly, the number of mutations in a region follows Poisson distribution 

$y \sim Pois(\lambda \mu)$

Use Gamma as its prior, 

$\lambda \sim Ga(\alpha, \alpha)$

Thus the posterior of $\lambda$ is 

$$
\begin{aligned}
 \lambda|y  & \propto P(\lambda) \times P(y|\lambda \mu)  \\
   & \propto \lambda ^{\alpha+y-1} e^{-\lambda(\alpha+\mu)}
\end{aligned}
$$


$\lambda|y \sim Ga(\alpha+y, \alpha+\mu)$



## Categorization

Human genome has 3B bases, even for 100 bp windows, the computation is still expensive. To speed up, one way is to put all windows with similar features into one category and treat the whole category as a single unit. Suppose we have $P$ binary features (continuous features could be discretized into discrete values). Totally it is going to be $2^P$ feature categories.  Usually $2^P << \frac{3B}{L}$, $L$ is window length. 

Let $c$ index category. $Y_c$ is the total number of mutations, $\mu_{c0}$ is the baseline mutation rate, $X_c$ is the feature covariates. Then $Y_c \sim Pois(\mu_{c0}e^{X_c\beta})$ with the probability mass function $P(Y_c|\beta)=\frac{\mu_c^{Y_c}e^{-\mu_c}}{Y_c!}$, where $\mu_c=\mu_{c0}e^{X_c\beta}$. 


The likelihood function is 

$$
\begin{aligned}
 logP(Y|\beta) & =log \prod_c P(Y_c|\beta) \\
 &=\sum_c[Y_clog(\mu_c)-\mu_c-log(Y_c!) ]\\
 &=\sum_c\{Y_c[log(\mu_{c0})+X_c\beta]-\mu_{c0}e^{X_c\beta}-log(Y_c!) \} \\
 &=\sum_c\{Y_c(X_c\beta)-\mu_{c0}e^{X_c\beta} \}+constant
\end{aligned}
$$


Let $f(\beta)=\sum_c\{Y_c(X_c\beta)-\mu_{c0}e^{X_c\beta} \}$ be the objective function to be optimized over $\beta$. 
$\frac{\partial f(\beta)}{\partial \beta_i}=\sum_c (Y_c(X_{ic})-\mu_{c0}X_{ic}e^{X_c\beta})$, $i=1, \cdots, P$. 

<!-- Insert the session information into the document -->
```{r session-info}
```
