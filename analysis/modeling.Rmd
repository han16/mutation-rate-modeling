---
title: "Modeling"
author: "Shengtong Han"
date: YYYY-MM-DD
output: html_document
---



## Base level


At every genomic locus, observed number of mutations, $y_i$ is modeled as Poisson distribution as 

$y_i \sim Pois(\mu_i)$

There are several covariates affecting the mutation rate, such as tri-nucleotide context, parents' age, etc. To relate the mutation rate to covariates $X_i$, Poisson regression could be one way to do that 

$log(E(y_i|X_i))=log(\mu_i)=X_i^T\beta$

Thus 

$\mu_i=e^{X_i^T\beta}$. 


The likelihood function is 

$$
\begin{aligned} 
L(\beta|Y)&=\prod_i\frac{[e^{X_i^T\beta}]^{Y_i}e^{-e^{X_i^T\beta}}}{Y_i!}\\
&=e^{\sum_i[X_i^T\beta Y_i-e^{X_i^T\beta}]} \times constant
\end{aligned}
$$

The log likelihood is 

$$
\begin{aligned}
l(\beta)&=\sum_i[X_i^T\beta Y_i-e^{X_i^T\beta}]+constant\\
&=\sum_i(X_i^T\beta)Y_i-\sum_ie^{X_i^T\beta}+constant
\end{aligned}
$$



## Region level

It's computationally hard to infer the mutation rate at single base since there are 3B bases in human genome. So consider the window level. Within  a window, collapse all bases together, denote $Y$ by the total number of mutations, assume $X_i$ are the same across all bases. Within a window, assuming $Y_i\sim Pois(\mu_i)$ are indepedent poisson random variables, the sum $Y=\sum_iY_i \sim Pois (\sum_i\mu_i)$


Considering baseline mutation rate $\mu_{i0}$ at every base $i$, then $Y \sim Pois(\sum_i \mu_{i0} \mu_i)$, where $\sum_i \mu_{i0}\mu_i=\sum_i\mu_{i0}e^{X_i^T\beta}=e^{X^T\beta}\sum_i\mu_{i0}$, assuming $x_i^T\beta$ are the same across all bases in the window and $\sum_i \mu_{i0}$ is the total baseline mutation for the window. Then $Y_j \sim Pois(\mu_{j0}e^{X_j^T\beta})$


The likelihood funciton is 


$$
\begin{aligned} 
L(\beta|Y)=\prod_j\frac{[\mu_{j0}e^{X_j^T\beta}]^{Y_j}e^{-\mu_{j0}e^{X_j^T\beta}}}{Y_j!}
\end{aligned}
$$


and

* $Y_j$; total number of mutations in  window $j$
* $X_j$: a vector of covariates for the window, assuming the same acorss all bases in the window





And the log likelihood function is 

$$
\begin{aligned}
l(\beta)=\sum_j[Y_jlog(\mu_{j0}e^{X_j^T\beta})]-\sum_j[\mu_{j0}e^{X_j^T\beta}]+constant
\end{aligned}
$$



## Categorization

Human genome has 3B bases, even for 100 bp windows, the computation is still expensive. To speed up, one way is to put all windows with similar features into one category and treat the whole category as a single unit. Suppose we have $P$ binary features (continuous features could be discretized into discrete values). Totally it is going to be $2^P$ feature categories.  Usually $2^P << \frac{3B}{L}$, $L$ is window length. 

Let $c$ index category. $Y_c$ is the total number of mutations, $\mu_{c0}$ is the baseline mutation rate, $X_c$ is the feature covariates. 


The likelihood function is 

$$
\begin{aligned}
 logP(Y|\beta) & = \sum_j[Y_jlog(\mu_{j0}e^{X_j^T\beta})]-\sum_j[\mu_{j0}e^{X_j^T\beta}]+constant(following ~LH~of~region~level)\\
 &=\sum_c\{Y_c(X_c^T\beta)-\mu_{c0}e^{X_c^T\beta} \}+constant
\end{aligned}
$$

* $\mu_{c0}=\sum_j\mu_{j0}$ in category $c$.
* The last equation is because for category $c$, all $X_j=X_c$ are the same, so $\sum_jY_j(X_j^T\beta)=X_c^T\beta \sum_jY_j=Y_c(X_c^T\beta)$. 

Thus $Y_c\sim Pois(\mu_{c0}e^{X_c^T\beta})$. Another way to understand it is that since $Y_j \sim Pois(\mu_{j0}e^{X_j^T\beta})$, in category $c$, the sum of $\sum_j Y_j \sim Pois(\sum_j \mu_{j0}e^{X_j^T\beta})$, where $\sum_j \mu_{j0}e^{X_j^T\beta}=e^{X_c\beta} \sum_j \mu_{j0}=\mu_{c0}e^{X_c\beta}$, assuming $Y_j$ are independent.   



### Likelihood and derivative 


Let $f(\beta)=\sum_c\{Y_c(X_c^T\beta)-\mu_{c0}e^{X_c^T\beta} \}$ be the objective function to be optimized over $\beta$. 
$\frac{\partial f(\beta)}{\partial \beta_i}=\sum_c (Y_c(X_{ic})-\mu_{c0}X_{ic}e^{X_c^T\beta})$, $i=1, \cdots, P$, and 

$\frac{\partial f(\beta)}{\partial \beta_0}=\sum_c (Y_c-\mu_{c0}e^{X_c^T\beta})$. 


## Simulations 

The model generating the data is 

$y \sim Pois(\mu_0e^{\beta_0+\beta_1X})$


### Constant baseline mutation rate $\mu_0$

#### Use true baseline mutation rate as offset 


```{r, echo=F}
cate.fr=function(beta)
{
cova.matx=as.matrix(cbind(rep(1,nrow(cate.matrix)), cate.matrix[,2:(1+feature_number)]))
sum.lkhd=cate.matrix[,1]*cova.matx%*%beta-baseline.mutation*exp(cova.matx%*%beta)
 return(sum(sum.lkhd))
}

cate.grr=function(beta)
{
 partial.deriv=numeric(1+feature_number)
 cova.matx=as.matrix(cbind(rep(1,nrow(cate.matrix)), cate.matrix[,2:(1+feature_number)]))
 for (i in 1:feature_number)
  {
    sum.fea=cate.matrix[,1]*cate.matrix[,(1+i)]-baseline.mutation*cate.matrix[,(1+i)]*exp(cova.matx%*%beta)
  partial.deriv[1+i]=sum(sum.fea)
  }
  partial.deriv[1]=sum(cate.matrix[,1]-baseline.mutation*exp(cova.matx%*%beta))

 return(partial.deriv)
}


fr=function(beta)
{
cova.matx=as.matrix(cbind(rep(1, nrow(discrete.feature)), discrete.feature[,2:(1+feature_number)]))
sum.lkhd=discrete.feature[,1]*cova.matx%*%beta-baseline.mutation.before.cate*exp(cova.matx%*%beta)
 return(sum(sum.lkhd))
}

grr=function(beta)
{
 partial.deriv=numeric(1+feature_number)
 cova.matx=as.matrix(cbind(rep(1, nrow(discrete.feature)), discrete.feature[,2:(1+feature_number)]))
 for (i in 1:feature_number)
  {
    sum.fea=discrete.feature[,1]*discrete.feature[,(1+i)]-baseline.mutation.before.cate*discrete.feature[,(1+i)]*exp(cova.matx%*%beta)
  partial.deriv[1+i]=sum(sum.fea)
  }
  partial.deriv[1]=sum(discrete.feature[,1]-baseline.mutation.before.cate*exp(cova.matx%*%beta))
 return(partial.deriv)
}


```


```{r, echo=T, warning=FALSE, results='hide', cache=T}
#rm(list=ls())
set.seed(1000)
n <- 10000
baseline.rate=0.01
#regression coefficients
 beta0 <- 0.1
 beta1 <- log(2)
#generate covariate values
 x <- rbinom(n, 1, prob=0.5)
#compute mu's
mu <- exp(beta0 + beta1 * x)*baseline.rate
#generate Y-values
 y <- rpois(n=n, lambda=mu)
   #data set
 data <- data.frame(y=y, x=x)
 y0=sum(data$y[data$x==0]); y1=sum(data$y[data$x==1])
 cate.data=data.frame(y=c(y0,y1), x=c(0,1))
 fit=glm(data$y~data$x+offset(log(rep(baseline.rate, n))), family=poisson())
 cate.fit=glm(cate.data$y~cate.data$x+offset(log(c(baseline.rate*sum(x==cate.data$x[1]), baseline.rate*sum(x==cate.data$x[2])))), family=poisson())
fit.conf=confint(fit)
cate.fit.conf=confint(cate.fit)
```

```{r, echo=F}
method=c("M11", "M12", "M21", "M22")
para.est=matrix(nrow=2, ncol=2)
para.est[1,]=c(fit$coefficients[1], fit$coefficients[2])
para.est[2,]=c(cate.fit$coefficients[1], cate.fit$coefficients[2])
par(mfrow=c(1,2), oma = c(0, 0, 2, 0))
barCenters=barplot(para.est[,1], beside=F, ylim=c(0, 0.15), col=c("red", "darkblue"),  xlab="",  main=expression(paste(beta[0])))
abline(h=beta0, lty=4)
segments(barCenters, c(fit.conf[1,1], cate.fit.conf[1,1]), barCenters,
        c(fit.conf[1,2], cate.fit.conf[1,2]) , lwd = 1.5)

arrows(barCenters, c(fit.conf[1,1], cate.fit.conf[1,1]), barCenters,
        c(fit.conf[1,2], cate.fit.conf[1,2]) , lwd = 1.5, angle = 90,
       code = 3, length = 0.05)
######## estimate by optim 
feature_number=1
cate.matrix=cate.data
baseline.mutation=c(baseline.rate*sum(x==cate.data$x[1]), baseline.rate*sum(x==cate.data$x[2]))
baseline.mutation.before.cate=baseline.rate
discrete.feature=data
para.initial=rep(0.1, (1+feature_number))
para.est.optim.cate=optim(para.initial, cate.fr, cate.grr, method="BFGS", control=list(fnscale=-1))
para.est.optim.before.cate=optim(para.initial, fr, grr, method="BFGS", control=list(fnscale=-1))
################
beta1.est=matrix(nrow=length(method), ncol=1)
beta1.est[1,]=fit$coefficients[2]
beta1.est[2,]=cate.fit$coefficients[2]
beta1.est[3,]=para.est.optim.before.cate$par[2]
beta1.est[4,]=para.est.optim.cate$par[2]

barcenters=barplot(beta1.est, beside=T, ylim=c(0, 1.2), col=c("red", "darkblue", "green", "darkgreen"),  xlab="", legend=method, main=expression(paste(beta[1])), args.legend = list(x ='topright', bty='n', inset=c(-0.07,0), cex=0.8))
abline(h=beta1, lty=4)
segments(barcenters[1:2,1], c(fit.conf[2,1], cate.fit.conf[2,1]), barcenters[1:2,1],
        c(fit.conf[2,2], cate.fit.conf[2,2]) , lwd = 1.5)

arrows(barcenters[1:2,], c(fit.conf[2,1], cate.fit.conf[2,1]), barcenters[1:2,],
        c(fit.conf[2,2], cate.fit.conf[2,2]) , lwd = 1.5, angle = 90,
       code = 3, length = 0.05)
title(paste("Estimate comparison with sample size of", n, sep=" ")  , outer=TRUE)
```

* sample size, i.e. number of windows $N=10^4$
* baseline rate is constant across all windows $\mu_0=0.01$.
* $\beta_0=0.1, \beta_1=log(2)$. 
* M11 and M12 are GLM without and with categorization; M21,  M22 are optim without and with categorization.  $\widehat{\beta}_{11}=\widehat{\beta}_{12}$ and $\widehat{\beta}_{21}=\widehat{\beta}_{22}$ and the difference between M11 and M21 are too minor to visualize 






```{r, echo=F, warning=FALSE, results='hide', cache=T}
#rm(list=ls())
set.seed(1000)
n <- 1000000
baseline.rate=0.01
#regression coefficients
 beta0 <- 0.1
 beta1 <- log(2)
#generate covariate values
 x <- rbinom(n, 1, prob=0.5)
#compute mu's
mu <- exp(beta0 + beta1 * x)*baseline.rate
#generate Y-values
 y <- rpois(n=n, lambda=mu)
   #data set
 data <- data.frame(y=y, x=x)
 y0=sum(data$y[data$x==0]); y1=sum(data$y[data$x==1])
 cate.data=data.frame(y=c(y0,y1), x=c(0,1))
 fit=glm(data$y~data$x+offset(log(rep(baseline.rate, n))), family=poisson())
 cate.fit=glm(cate.data$y~cate.data$x+offset(log(c(baseline.rate*sum(x==cate.data$x[1]), baseline.rate*sum(x==cate.data$x[2])))), family=poisson())
fit.conf=confint(fit)
cate.fit.conf=confint(cate.fit)
```

```{r, echo=F}
para.est=matrix(nrow=2, ncol=2)
para.est[1,]=c(fit$coefficients[1], fit$coefficients[2])
para.est[2,]=c(cate.fit$coefficients[1], cate.fit$coefficients[2])
par(mfrow=c(1,2), oma = c(0, 0, 2, 0))
barCenters1=barplot(para.est[,1], beside=F, ylim=c(0, 0.15), col=c("red", "darkblue"), legend=c("No cate", "With cate"),  xlab="",  main=expression(paste(beta[0])))
abline(h=beta0, lty=4)
segments(barCenters1, c(fit.conf[1,1], cate.fit.conf[1,1]), barCenters1,
        c(fit.conf[1,2], cate.fit.conf[1,2]) , lwd = 1.5)

arrows(barCenters1, c(fit.conf[1,1], cate.fit.conf[1,1]), barCenters1,
        c(fit.conf[1,2], cate.fit.conf[1,2]) , lwd = 1.5, angle = 90,
       code = 3, length = 0.05)

######## estimate by optim 
feature_number=1
cate.matrix=cate.data
baseline.mutation=c(baseline.rate*sum(x==cate.data$x[1]), baseline.rate*sum(x==cate.data$x[2]))
baseline.mutation.before.cate=baseline.rate
discrete.feature=data
para.initial=rep(0.1, (1+feature_number))
para.est.optim.cate=optim(para.initial, cate.fr, cate.grr, method="BFGS", control=list(fnscale=-1))
para.est.optim.before.cate=optim(para.initial, fr, grr, method="BFGS", control=list(fnscale=-1))
################
beta1.est=matrix(nrow=length(method), ncol=1)
beta1.est[1,]=fit$coefficients[2]
beta1.est[2,]=cate.fit$coefficients[2]
beta1.est[3,]=para.est.optim.before.cate$par[2]
beta1.est[4,]=para.est.optim.cate$par[2]

barcenters2=barplot(beta1.est, beside=T, ylim=c(0, 1.2), col=c("red", "darkblue", "green", "darkgreen"),  xlab="", legend=method, main=expression(paste(beta[1])), args.legend = list(x ='topright', bty='n', inset=c(-0.07,0), cex=0.8))
abline(h=beta1, lty=4)
segments(barcenters2[1:2,1], c(fit.conf[2,1], cate.fit.conf[2,1]), barcenters2[1:2,1],
        c(fit.conf[2,2], cate.fit.conf[2,2]) , lwd = 1.5)

arrows(barcenters2[1:2,], c(fit.conf[2,1], cate.fit.conf[2,1]), barcenters2[1:2,],
        c(fit.conf[2,2], cate.fit.conf[2,2]) , lwd = 1.5, angle = 90,
       code = 3, length = 0.05)
title(paste("Estimate comparison with sample size of", n, sep=" ")  , outer=TRUE)

```

* sample size, i.e. number of windows $N=10^6$
* baseline rate is constant across all windows $\mu_0=0.01$.
* $\beta_0=0.1, \beta_1=log(2)$. 



When  there are 2 covariates 



```{r, echo=F, warning=FALSE, results='hide', cache=T}
#rm(list=ls())
set.seed(1000)
n <- 1000000
baseline.rate=0.01
#regression coefficients
 beta0 <- 0.1
 beta1 <- log(2); beta2=log(5)
#generate covariate values
 x1 <- rbinom(n, 1, prob=0.5); x2=rbinom(n, 1, prob=0.2)
#compute mu's
mu <- exp(beta0 + beta1 * x1+beta2*x2)*baseline.rate
#generate Y-values
 y <- rpois(n=n, lambda=mu)
   #data set
 data <- data.frame(y=y, x1=x1, x2=x2)
 y00=sum(data$y[data$x1==0 & data$x2==0]); y01=sum(data$y[data$x1==0 & data$x2==1])
 y10=sum(data$y[data$x1==1 & data$x2==0]); y11=sum(data$y[data$x1==1 & data$x2==1])
 cate.data=data.frame(y=c(y00,y01, y10, y11), x1=c(0,0,1,1), x2=c(0,1,0,1))
 fit=glm(data$y~data$x1+data$x2+offset(log(rep(baseline.rate, n))), family=poisson())
 offset.term=c(baseline.rate*nrow(data[data$x1==0 & data$x2==0,]), baseline.rate*nrow(data[data$x1==0 & data$x2==1,]), baseline.rate*nrow(data[data$x1==1 & data$x2==0,]), baseline.rate*nrow(data[data$x1==1 & data$x2==1,]))
 cate.fit=glm(cate.data$y~cate.data$x1+cate.data$x2+offset(log(offset.term)), family=poisson())
fit.conf=confint(fit)
cate.fit.conf=confint(cate.fit)
```



```{r, echo=F}
para.est=matrix(nrow=2, ncol=2)
para.est[1,]=c(fit$coefficients[1], fit$coefficients[2])
para.est[2,]=c(cate.fit$coefficients[1], cate.fit$coefficients[2])
par(mfrow=c(1,3), oma = c(0, 0, 2, 0))
barCenters1=barplot(para.est[,1], beside=F, ylim=c(0, 0.15), col=c("red", "darkblue"), legend=c("No cate", "With cate"),  xlab="",  main=expression(paste(beta[0])))
abline(h=beta0, lty=4)
segments(barCenters1, c(fit.conf[1,1], cate.fit.conf[1,1]), barCenters1,
        c(fit.conf[1,2], cate.fit.conf[1,2]) , lwd = 1.5)

arrows(barCenters1, c(fit.conf[1,1], cate.fit.conf[1,1]), barCenters1,
        c(fit.conf[1,2], cate.fit.conf[1,2]) , lwd = 1.5, angle = 90,
       code = 3, length = 0.05)

######## estimate by optim 
feature_number=2
cate.matrix=cate.data
baseline.mutation=offset.term
baseline.mutation.before.cate=baseline.rate
discrete.feature=data
para.initial=rep(0.1, (1+feature_number))
para.est.optim.cate=optim(para.initial, cate.fr, cate.grr, method="BFGS", control=list(fnscale=-1))
para.est.optim.before.cate=optim(para.initial, fr, grr, method="BFGS", control=list(fnscale=-1))
################
beta1.est=matrix(nrow=length(method), ncol=1)
beta1.est[1,]=fit$coefficients[2]
beta1.est[2,]=cate.fit$coefficients[2]
beta1.est[3,]=para.est.optim.before.cate$par[2]
beta1.est[4,]=para.est.optim.cate$par[2]

barcenters2=barplot(beta1.est, beside=T, ylim=c(0, 1.2), col=c("red", "darkblue", "green", "darkgreen"),  xlab="", legend=method, main=expression(paste(beta[1])), args.legend = list(x ='topright', bty='n', inset=c(-0.07,0), cex=0.8))
abline(h=beta1, lty=4)
segments(barcenters2[1:2,1], c(fit.conf[2,1], cate.fit.conf[2,1]), barcenters2[1:2,1],
        c(fit.conf[2,2], cate.fit.conf[2,2]) , lwd = 1.5)

arrows(barcenters2[1:2,], c(fit.conf[2,1], cate.fit.conf[2,1]), barcenters2[1:2,],
        c(fit.conf[2,2], cate.fit.conf[2,2]) , lwd = 1.5, angle = 90,
       code = 3, length = 0.05)
title(paste("Estimate comparison with sample size of", n, sep=" ")  , outer=TRUE)


################
beta2.est=matrix(nrow=length(method), ncol=1)
beta2.est[1,]=fit$coefficients[3]
beta2.est[2,]=cate.fit$coefficients[3]
beta2.est[3,]=para.est.optim.before.cate$par[3]
beta2.est[4,]=para.est.optim.cate$par[3]

barcenters3=barplot(beta2.est, beside=T, ylim=c(0, 2), col=c("red", "darkblue", "green", "darkgreen"),  xlab="", legend=method, main=expression(paste(beta[2])), args.legend = list(x ='topright', bty='n', inset=c(-0.07,0), cex=0.8))
abline(h=beta2, lty=4)
segments(barcenters3[1:2,1], c(fit.conf[3,1], cate.fit.conf[3,1]), barcenters3[1:2,1],
        c(fit.conf[3,2], cate.fit.conf[3,2]) , lwd = 1.5)

arrows(barcenters3[1:2,], c(fit.conf[3,1], cate.fit.conf[3,1]), barcenters3[1:2,],
        c(fit.conf[3,2], cate.fit.conf[3,2]) , lwd = 1.5, angle = 90,
       code = 3, length = 0.05)
title(paste("Estimate comparison with sample size of", n, sep=" ")  , outer=TRUE)

```

* sample size, i.e. number of windows $N=10^6$
* baseline rate is constant across all windows $\mu_0=0.01$.
* $\beta_0=0.1, \beta_1=log(2), \beta_2=log(5)$. 



#####################################################
#####################################################

```{r, echo=F, warning=FALSE, results='hide', cache=T}
#rm(list=ls())
set.seed(1000)
n <- 1000000
baseline.rate=0.01
#regression coefficients
 beta0 <- 0.1
 beta1 <- log(2); beta2=log(5)
#generate covariate values
 x1 <- rbinom(n, 1, prob=0.5); x2=rbinom(n, 1, prob=0.2)
#compute mu's
mu <- exp(beta0 + beta1 * x1+beta2*x2)*baseline.rate
#generate Y-values
 y <- rpois(n=n, lambda=mu)
   #data set
 data <- data.frame(y=y, x1=x1, x2=x2)
 ####################
 y00=sum(data$y[data$x1==0 & data$x2==0]); y01=sum(data$y[data$x1==0 & data$x2==1])
 y10=sum(data$y[data$x1==1 & data$x2==0]); y11=sum(data$y[data$x1==1 & data$x2==1])
 cate.data=data.frame(y=c(y00,y01, y10, y11), x1=c(0,0,1,1), x2=c(0,1,0,1))
 fit=glm(data$y~data$x1+data$x2+offset(log(rep(baseline.rate, n))), family=poisson())
 offset.term=c(baseline.rate*nrow(data[data$x1==0 & data$x2==0,]), baseline.rate*nrow(data[data$x1==0 & data$x2==1,]), baseline.rate*nrow(data[data$x1==1 & data$x2==0,]), baseline.rate*nrow(data[data$x1==1 & data$x2==1,]))
 cate.fit=glm(cate.data$y~cate.data$x1+cate.data$x2+offset(log(offset.term)), family=poisson())
fit.conf=confint(fit)
cate.fit.conf=confint(cate.fit)
#################### 
data1=data[1:(n/2),]; data2=data[(1+n/2):n,]
y00_1=sum(data1$y[data1$x1==0 & data1$x2==0]); y01_1=sum(data1$y[data1$x1==0 & data1$x2==1])
y10_1=sum(data1$y[data1$x1==1 & data1$x2==0]); y11_1=sum(data1$y[data1$x1==1 & data1$x2==1])
cate.data1=data.frame(y=c(y00_1,y01_1, y10_1, y11_1), x1=c(0,0,1,1), x2=c(0,1,0,1))
y00_2=sum(data2$y[data2$x1==0 & data2$x2==0]); y01_2=sum(data2$y[data2$x1==0 & data2$x2==1])
y10_2=sum(data2$y[data2$x1==1 & data2$x2==0]); y11_2=sum(data2$y[data2$x1==1 & data2$x2==1])
cate.data2=data.frame(y=c(y00_2,y01_2, y10_2, y11_2), x1=c(0,0,1,1), x2=c(0,1,0,1))
cate.data.split=rbind(cate.data1, cate.data2)

offset.term1=c(baseline.rate*nrow(data1[data1$x1==0 & data1$x2==0,]), baseline.rate*nrow(data1[data1$x1==0 & data1$x2==1,]), baseline.rate*nrow(data1[data1$x1==1 & data1$x2==0,]), baseline.rate*nrow(data1[data1$x1==1 & data1$x2==1,]))

offset.term2=c(baseline.rate*nrow(data2[data2$x1==0 & data2$x2==0,]), baseline.rate*nrow(data2[data2$x1==0 & data2$x2==1,]), baseline.rate*nrow(data2[data2$x1==1 & data2$x2==0,]), baseline.rate*nrow(data2[data2$x1==1 & data2$x2==1,]))
cate.split.fit=glm(cate.data.split$y~cate.data.split$x1+cate.data.split$x2+offset(log(c(offset.term1, offset.term2))), family=poisson())
cate.split.fit.conf=confint(cate.split.fit)
```



```{r, echo=F}
par(mfrow=c(1,2), oma = c(0, 0, 2, 0))
beta1.est=matrix(nrow=3, ncol=1)
beta1.est[1,]=fit$coefficients[2]
beta1.est[2,]=cate.fit$coefficients[2]
beta1.est[3,]=cate.split.fit$coefficients[2]

barcenters2=barplot(beta1.est, beside=T, ylim=c(0, 1.2), col=c("red", "blue", "green"),  xlab="", legend=c("No cate", "Cate", "SplitCateComb"), main=expression(paste(beta[1])), args.legend = list(x ='topright', bty='n', inset=c(-0.07,0), cex=0.8))
abline(h=beta1, lty=4)
segments(barcenters2[1:3,1], c(fit.conf[2,1], cate.fit.conf[2,1], cate.split.fit.conf[2,1]),barcenters2[1:3,1], c(fit.conf[2,2], cate.fit.conf[2,2], cate.split.fit.conf[2,2]) , lwd = 1.5)

arrows(barcenters2[1:3,1], c(fit.conf[2,1], cate.fit.conf[2,1], cate.split.fit.conf[2,1]),barcenters2[1:3,1], c(fit.conf[2,2], cate.fit.conf[2,2], cate.split.fit.conf[2,2]) , lwd = 1.5, angle = 90,
       code = 3, length = 0.05)
title(paste("Estimate comparison with sample size of", n, sep=" ")  , outer=TRUE)


################
beta2.est=matrix(nrow=3, ncol=1)
beta2.est[1,]=fit$coefficients[3]
beta2.est[2,]=cate.fit$coefficients[3]
beta2.est[3,]=cate.split.fit$coefficients[3]

barcenters3=barplot(beta2.est, beside=T, ylim=c(0, 2.2), col=c("red", "darkblue", "green"),  xlab="", legend=c("No cate", "Cate", "SplitCateComb"), main=expression(paste(beta[2])), args.legend = list(x ='topright', bty='n', inset=c(-0.07,0), cex=0.8))
abline(h=beta2, lty=4)
segments(barcenters3[1:3,1], c(fit.conf[3,1], cate.fit.conf[3,1], cate.split.fit.conf[3,1]), barcenters3[1:3,1],
        c(fit.conf[3,2], cate.fit.conf[3,2], cate.split.fit.conf[3,2]) , lwd = 1.5)

arrows(barcenters3[1:3,1], c(fit.conf[3,1], cate.fit.conf[3,1], cate.split.fit.conf[3,1]), barcenters3[1:3,1],
        c(fit.conf[3,2], cate.fit.conf[3,2], cate.split.fit.conf[3,2]) , lwd = 1.5, angle = 90,
       code = 3, length = 0.05)
title(paste("Estimate comparison with sample size of", n, sep=" ")  , outer=TRUE)

```


* This figure shows that three different manipulations of the data give the same estimate by GLM: (1) No categorization (2) use categorization (3) first split the original data into two sub data sets, for each sub-data, do categorization, then combine them together to use GLM. The third way allows to do categorization on each single chromosome, then combine them to use GLM.  


#### Use estimated baseline mutation rate 

In most cases, we never know the true baseline mutation rate, so we may have to use their estimates 

```{r, echo=F, eval=F}
fit=glm(data$y~data$x+offset(log(rep(sum(data$y)/n, n))), family=poisson())
cate.fit=glm(cate.data$y~cate.data$x+offset(log(c(sum(cate.data$y)/n*sum(x==cate.data$x[1]), sum(cate.data$y)/n*sum(x==cate.data$x[2])))), family=poisson())
 
```

```{r, echo=F, eval=F}
para.est=matrix(nrow=2, ncol=2)
para.est[1,]=c(fit$coefficients[1], fit$coefficients[2])
para.est[2,]=c(cate.fit$coefficients[1], cate.fit$coefficients[2])
par(mfrow=c(1,2), oma = c(0, 0, 2, 0))
#barCenters=barplot(para.est[,1], beside=F, ylim=c(min(para.est[,1], beta0, 0), max(para.est[,1], beta0, 0)), col=c("red", "darkblue"),  xlab="",  main=expression(paste(beta[0])))
plot(para.est[,1],ylim=c(min(para.est[,1], beta0, 0), max(para.est[,1], beta0, 0)), xlab="",  xaxt='n',  main=expression(paste(beta[0])), ylab="", col=c("red", "darkblue"), pch=16)

barcenters=barplot(para.est[,2], beside=F, ylim=c(0, 1.2), col=c("red", "darkblue"),  xlab="", legend=c("No cate", "With cate"), main=expression(paste(beta[1])))
abline(h=beta1, lty=4)
segments(barCenters, c(fit.conf[2,1], cate.fit.conf[2,1]), barCenters,
        c(fit.conf[2,2], cate.fit.conf[2,2]) , lwd = 1.5)

arrows(barCenters, c(fit.conf[2,1], cate.fit.conf[2,1]), barCenters,
        c(fit.conf[2,2], cate.fit.conf[2,2]) , lwd = 1.5, angle = 90,
       code = 3, length = 0.05)
title(paste("Estimate comparison with sample size of", n, sep=" ")  , outer=TRUE)
```

* with estimated baseline mutation rate as offset, intercept esmtiate is not correct, but $\widehat{\beta_1}$ is good. 


### Variable baseline mutatiom rate $\mu_{i0}$

#### use true baseline mutation rate 


```{r, echo=F, warning=F, results='hide', cache=T}
#rm(list=ls())
set.seed(1000)
n <- 1000000
baseline.rate=rbeta(n, 1, 100)
#regression coefficients
 beta0 <- 0.1
 beta1 <- log(2)
#generate covariate values
 x <- rbinom(n, 1, prob=0.5)
#compute mu's
mu <- exp(beta0 + beta1 * x)*baseline.rate
#generate Y-values
 y <- rpois(n=n, lambda=mu)
   #data set
 data <- data.frame(y=y, x=x)
 y0=sum(data$y[data$x==0]); y1=sum(data$y[data$x==1])
 cate.data=data.frame(y=c(y0,y1), x=c(0,1))
 fit=glm(data$y~data$x+offset(log(baseline.rate)), family=poisson())
 cate.fit=glm(cate.data$y~cate.data$x+offset(log(c(sum(baseline.rate[x==cate.data$x[1]]), sum(baseline.rate[x==cate.data$x[2]])))), family=poisson())
fit.conf=confint(fit)
cate.fit.conf=confint(cate.fit)
```

```{r, echo=F}
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}
plot(density(mu), main=expression(paste("Density of generated", mu[i0], sep=" ")), xlab="")
#abline(v=Mode(mu), col=2)
```

* $\mu_{i0}$ is generated by $\mu_{i0} \sim rbeta(n, 1, 100)$


```{r, echo=F}
para.est=matrix(nrow=2, ncol=2)
para.est[1,]=c(fit$coefficients[1], fit$coefficients[2])
para.est[2,]=c(cate.fit$coefficients[1], cate.fit$coefficients[2])
par(mfrow=c(1,2), oma = c(0, 0, 2, 0))
barCenters=barplot(para.est[,1], beside=F, ylim=c(0, 0.15), col=c("red", "darkblue"),  xlab="",  main=expression(paste(beta[0])))
abline(h=beta0, lty=4)
segments(barCenters, c(fit.conf[1,1], cate.fit.conf[1,1]), barCenters,
        c(fit.conf[1,2], cate.fit.conf[1,2]) , lwd = 1.5)

arrows(barCenters, c(fit.conf[1,1], cate.fit.conf[1,1]), barCenters,
        c(fit.conf[1,2], cate.fit.conf[1,2]) , lwd = 1.5, angle = 90,
       code = 3, length = 0.05)

barcenters=barplot(para.est[,2], beside=F, ylim=c(0, 1.2), col=c("red", "darkblue"),  xlab="", legend=c("No cate", "With cate"), main=expression(paste(beta[1])))
abline(h=beta1, lty=4)
segments(barCenters, c(fit.conf[2,1], cate.fit.conf[2,1]), barCenters,
        c(fit.conf[2,2], cate.fit.conf[2,2]) , lwd = 1.5)

arrows(barCenters, c(fit.conf[2,1], cate.fit.conf[2,1]), barCenters,
        c(fit.conf[2,2], cate.fit.conf[2,2]) , lwd = 1.5, angle = 90,
       code = 3, length = 0.05)
title(paste("Estimate comparison with sample size of", n, sep=" ")  , outer=TRUE)
```

#### use randomly generated  baseline mutation rate 



```{r, echo=T}
#fit=glm(data$y~data$x+offset(log(rep(sum(data$y)/n, n))), family=poisson())
fit=glm(data$y~data$x+offset(log(rbeta(n,1, 100))), family=poisson())
#cate.fit=glm(cate.data$y~cate.data$x+offset(log(c(sum(cate.data$y)/n*sum(x==cate.data$x[1]), sum(cate.data$y)/n*sum(x==cate.data$x[2])))), family=poisson())
cate.fit=glm(cate.data$y~cate.data$x+offset(log(rbeta(2,1,100 ))), family=poisson()) 

```

```{r, echo=F}
para.est=matrix(nrow=2, ncol=2)
para.est[1,]=c(fit$coefficients[1], fit$coefficients[2])
para.est[2,]=c(cate.fit$coefficients[1], cate.fit$coefficients[2])
par(mfrow=c(1,2), oma = c(0, 0, 2, 0))
#barCenters=barplot(para.est[,1], beside=F, ylim=c(min(para.est[,1], beta0, 0), max(para.est[,1], beta0, 0)), col=c("red", "darkblue"),  xlab="",  main=expression(paste(beta[0])))
plot(para.est[,1],ylim=c(min(para.est[,1], beta0, 0), max(para.est[,1], beta0, 0)), xlab="",  xaxt='n',  main=expression(paste(beta[0])), ylab="", col=c("red", "darkblue"), pch=16)
abline(h=beta0, lty=4)

barcenters=barplot(para.est[,2], beside=F, ylim=c(0, 1.2), col=c("red", "darkblue"),  xlab="", legend=c("No cate", "With cate"), main=expression(paste(beta[1])))
abline(h=beta1, lty=4)
segments(barCenters, c(fit.conf[2,1], cate.fit.conf[2,1]), barCenters,
        c(fit.conf[2,2], cate.fit.conf[2,2]) , lwd = 1.5)

arrows(barCenters, c(fit.conf[2,1], cate.fit.conf[2,1]), barCenters,
        c(fit.conf[2,2], cate.fit.conf[2,2]) , lwd = 1.5, angle = 90,
       code = 3, length = 0.05)
title(paste("Estimate comparison with sample size of", n, sep=" ")  , outer=TRUE)
```

* with estimated baseline mutation rate as offset, intercept esmtiate is not correct, but $\widehat{\beta_1}$ is good. 

<!-- Insert the session information into the document -->
```{r session-info}
```
